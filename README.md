# Cplusplus-Program
Class 370-Current/Emerging Trends 
Project Summary and Work Done
For this project, I built an intelligent pirate agent for a treasure hunt game. The goal of the pirate is to navigate a grid-like environment, avoid obstacles, and reach the treasure before the player. I was given starter code that defined the game environment, including how states, actions, rewards, and the overall game loop worked. I also received code for things like rendering, movement rules, and basic agent structure. I wrote the core of the deep Q-learning (DQN) training loop myself. That included building the neural network model to approximate Q-values, implementing replay memory, choosing actions with an ε-greedy policy (balancing exploration and exploitation), updating Q-targets, and training the model over many episodes. In other words, I completed the learning logic that actually teaches the pirate how to move intelligently toward the treasure. 

Connection to Computer Science
Computer scientists design systems that solve real problems using computation. That matters because many real-world problems (like pathfinding, decision-making, prediction, optimization) are too large or too fast for humans to solve manually in real time. In this project, I approached the pirate’s navigation task the same way a computer scientist would: I defined the problem in terms of states (where the pirate is), actions (where it can move), goals (get the treasure), and rewards (positive for treasure, negative for bad moves). From there, I designed and implemented an algorithm that could learn a policy through trial and error. Instead of hardcoding a path, I created a system that learns its own behavior. That mindset—turning a real scenario into formal rules, data structures, and algorithms—is central to computer science. 

Problem-Solving Approach
My approach to problem solving in this project was iterative and data-driven. First, I broke the task into parts: environment, agent, learning loop. Then I identified what information the agent needed to make decisions (state representation), what choices it could legally make (action space), and how to score those choices (reward function). After that, I built and tuned the learning algorithm: training episodes, target updates, discount factor, exploration rate, etc. Finally, I evaluated performance by watching whether the pirate could consistently reach the treasure. This mirrors how computer scientists solve complex problems: define objectives, design algorithms, test, observe failures, and refine.

Ethical Responsibilities
Even though this is “just a game,” the ideas behind it apply directly to real AI systems that act in the world. That means there are ethical responsibilities to both the end user and the organization using the AI. First, the system should behave in a predictable and explainable way. If an AI is making decisions (especially in safety-critical settings), you need to understand why it makes those choices and what it was trained to optimize. Second, the reward function matters. In reinforcement learning, the agent will do whatever gets it the highest reward, even if that means exploiting loopholes. So you have a responsibility to design rewards that align with safe, fair, intended behavior. Finally, there’s responsibility around honesty: documenting what the model can and cannot do, and avoiding overstating performance. In a real deployment, that protects users from harm and protects the organization from relying on an AI system in the wrong context
